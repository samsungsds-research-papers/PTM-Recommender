{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a3dcd7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, dill\n",
    "import json\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "import ptm_recommender.graph_models.graph_util as util\n",
    "from ptm_recommender.graph_models.gcnn.gin_utils import graph_to_s2vgraphs\n",
    "\n",
    "torch.set_num_threads(2)\n",
    "torch.cuda.is_available = lambda : False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "DILL_PATH = '../ptm_model_bench/base_model_dataset/'\n",
    "MODEL_PATH = '../results/gcnn_ptm_model_bench/'\n",
    "PERFORMANCE_PATH = '../ptm_model_bench/performance/seen_base_models/'\n",
    "OUTPUT_NAME = 'result'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a3ae9a",
   "metadata": {},
   "source": [
    "## Recomendation on testsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c5b4b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic setup\n",
    "task_to_metric = {\n",
    "            \"mrpc\" : \"eval_accuracy\",  \"cola\" : \"eval_matthews_correlation\", #\"cola\" : \"eval_accuracy\",\n",
    "            \"rte\" :'eval_accuracy', \"sst2\" :'eval_accuracy', \"stsb\" :'eval_pearson',\n",
    "            \"wnli\" :'eval_accuracy', \"squad_v2\": \"f1\", \"mnli\": \"eval_accuracy\", \n",
    "            \"qnli\": \"eval_accuracy\", \"qqp\": \"eval_accuracy\"}\n",
    "\n",
    "base_model_list = [\n",
    "    \"albert-base-v2\", \n",
    "    \"albert-large-v2\",\n",
    "    \"bert-base-uncased\", \n",
    "    \"bert-large-uncased\", \n",
    "    \"distilbert-base-uncased\",\n",
    "    \"distilroberta-base\", \n",
    "    \"electra-base-discriminator\",\n",
    "    \"electra-large-discriminator\",\n",
    "    \"roberta-base\", \n",
    "    \"roberta-large\",\n",
    "    \"xlm-roberta-base\", \n",
    "    \"xlm-roberta-large\"\n",
    "]\n",
    "# Task for title\n",
    "task_title = {\n",
    "    \"cola\":'CoLA', \n",
    "    \"mrpc\":'MRPC',\n",
    "    \"rte\" :'RTE', \n",
    "    \"sst2\" :'SST2', \n",
    "    \"stsb\" :'STSB',\n",
    "    \"wnli\" :'WNLI', \n",
    "    \"squad_v2\": 'SQuADv2',\n",
    "    \"mnli\": 'MNLI', \n",
    "    \"qnli\": 'QNLI', \n",
    "    \"qqp\": 'QQP'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b7dbc08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = list(task_title.keys())\n",
    "tasks = ['cola', 'mnli', 'mrpc', 'qnli', 'rte', 'stsb', 'sst2', 'qqp']\n",
    "output_name = 'result'\n",
    "performance_results_base_path='../ptm_model_bench/performance/merged_models/'\n",
    "import dill, torch\n",
    "import os,json\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "from matplotlib import gridspec\n",
    "import math\n",
    "\n",
    "def get_perf_and_logme(task):\n",
    "    model_results_base_path = f'../results/gcnn_ptm_model_bench/'  ## 이부분만 제가 쓰는 폴더\n",
    "    with  open(os.path.join(model_results_base_path,'{}_{}.dill'.format(output_name ,task)),'rb') as f:\n",
    "        model_result = dill.load(f)\n",
    "    with  open(os.path.join(performance_results_base_path, '{}_performance_score.json'.format(task)), 'r') as f:\n",
    "        performance = json.load(f)\n",
    "    try:\n",
    "        with  open(os.path.join(performance_results_base_path, '{}_logme.json'.format(task)), 'r') as f:\n",
    "            logme = json.load(f) \n",
    "    except:\n",
    "        logme=None\n",
    "    return model_result, performance, logme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0a00b041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cola : logme 1.04%, ptm_recommender 2.08%\n",
      "mnli : logme 10.19%, ptm_recommender 40.74%\n",
      "mrpc : logme 7.41%, ptm_recommender 11.11%\n",
      "qnli : logme 13.89%, ptm_recommender 0.93%\n",
      "rte : logme 4.63%, ptm_recommender 20.37%\n",
      "stsb : logme 43.52%, ptm_recommender 4.63%\n",
      "sst2 : logme 12.96%, ptm_recommender 12.04%\n",
      "qqp : logme 8.33%, ptm_recommender 7.41%\n",
      "squad_v2 : logme -, ptm_recommender 1.85%\n"
     ]
    }
   ],
   "source": [
    "tasks = list(task_title.keys())\n",
    "tasks = ['cola', 'mnli', 'mrpc', 'qnli', 'rte', 'stsb', 'sst2', 'qqp']\n",
    "for tdx, task in enumerate(tasks):\n",
    "    if task =='wnli' or task == 'squad_v2':\n",
    "        continue\n",
    "    model_result, performance, logme = get_perf_and_logme(task)\n",
    "    for x in model_result['total_result']:\n",
    "        x['logme'] = logme[x['model_name']]\n",
    "    perf_list =model_result['total_result']\n",
    "    logme_sorted = sorted(perf_list, key=lambda d:-d['logme'])\n",
    "    pred_acc_sorted = sorted(perf_list, key=lambda d:-d['pred_accuracy'])\n",
    "    true_acc_sorted = sorted(perf_list, key=lambda d:-d['true_accuracy'])\n",
    "    logme_selected = logme_sorted[0]['model_name']\n",
    "    gnn_based_selected = pred_acc_sorted[0]['model_name']\n",
    "\n",
    "    for idx, x in enumerate(true_acc_sorted):\n",
    "        if x['model_name'] ==  logme_selected:\n",
    "            logme_rank = (idx+1)/len(true_acc_sorted)\n",
    "        if x['model_name'] ==  gnn_based_selected:\n",
    "            ptm_recommender_rank = (idx+1)/len(true_acc_sorted)\n",
    "    print(task, \": logme {:.2f}%, ptm_recommender {:.2f}%\".format(logme_rank*100,  ptm_recommender_rank*100))\n",
    "\n",
    "task = 'squad_v2'\n",
    "model_result, performance, logme = get_perf_and_logme(task)\n",
    "perf_list =model_result['total_result']\n",
    "pred_acc_sorted = sorted(perf_list, key=lambda d:-d['pred_accuracy'])\n",
    "true_acc_sorted = sorted(perf_list, key=lambda d:-d['true_accuracy'])\n",
    "gnn_based_selected = pred_acc_sorted[0]['model_name']\n",
    "\n",
    "for idx, x in enumerate(true_acc_sorted):\n",
    "    if x['model_name'] ==  gnn_based_selected:\n",
    "        ptm_recommender_rank = (idx+1)/len(true_acc_sorted)\n",
    "print('squad_v2', \": logme {}, ptm_recommender {:.2f}%\".format('-',  ptm_recommender_rank*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f760d5c0",
   "metadata": {},
   "source": [
    "## Recomendation on seen base "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6af1b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_s2graph(base_model, performance, feature_dim ):\n",
    "    graph_info = [base_model]\n",
    "    graph_info_graphs = [x[0] for x in graph_info]\n",
    "    graph_info_params = [x[1] for x in graph_info]\n",
    "    graph_info_model_nm = [x[2] for x in graph_info]\n",
    "    for (G, p) in zip(graph_info_graphs, graph_info_params):\n",
    "        G.graph['feat_dim'] = feature_dim\n",
    "        param_keys = p.keys()\n",
    "        for u in util.node_iter(G):\n",
    "            label = util.node_dict(G)[u]['label']\n",
    "            if label in param_keys:\n",
    "                feature = p[label]\n",
    "                if feature.shape[0] != feature_dim:\n",
    "                    assert feature.shape[0] == feature_dim\n",
    "            else:\n",
    "                feature = torch.zeros(feature_dim).squeeze()\n",
    "            util.node_dict(G)[u]['feat'] = feature.float() \n",
    "    test_accuracies = [performance[nm][task_to_metric[task]] for nm in graph_info_model_nm if nm in performance.keys()]\n",
    "    test_graphs = graph_to_s2vgraphs(graph_info_graphs, test_accuracies, graph_info_model_nm)\n",
    "    return test_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2841944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_base_model_result(task, performance, prefix = 'base_'):\n",
    "    model_path = f'{MODEL_PATH}/model_{OUTPUT_NAME}_{task}.pth'\n",
    "   \n",
    "    model = torch.load(model_path, map_location=device)\n",
    "    model.device=device\n",
    "    \n",
    "    list_of_models = glob.glob(\"../ptm_model_bench/base_model_dataset/*\")\n",
    "    feature_dim = 128\n",
    "    result = {'total_result' : []}\n",
    "    for idx, model_path in enumerate(list_of_models):\n",
    "        \n",
    "        model_type =  model_path.split('/')[-1]\n",
    "        if model_type.startswith(prefix) is False:\n",
    "            continue\n",
    "        with open(model_path, 'rb') as f:\n",
    "            base_model_dataset=dill.load(f)\n",
    "        \n",
    "        for base_model in base_model_dataset:\n",
    "            if base_model[2] not in performance.keys():\n",
    "                continue\n",
    "            test_graphs = transform_to_s2graph(base_model, performance, feature_dim)\n",
    "            y_pred = model(test_graphs)\n",
    "        model_nm = base_model_dataset[0][2]\n",
    "        true_accuracy = performance[model_nm][task_to_metric[task]] if task!='squad_v2' \\\n",
    "                        else performance[model_nm][task_to_metric[task]]/100\n",
    "        result['total_result'].append({'true_accuracy': true_accuracy,\n",
    "                             'pred_accuracy': y_pred.view(-1).detach().cpu().numpy()[0],\n",
    "                             'model_name': base_model_dataset[0][2]})\n",
    "    return result, test_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1d20994d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cola : logme 8.33%, ptm_recommender 8.33%\n",
      "mnli : logme 8.33%, ptm_recommender 16.67%\n",
      "mrpc : logme 58.33%, ptm_recommender 16.67%\n",
      "qnli : logme 50.00%, ptm_recommender 8.33%\n",
      "rte : logme 58.33%, ptm_recommender 8.33%\n",
      "stsb : logme 50.00%, ptm_recommender 16.67%\n",
      "sst2 : logme 66.67%, ptm_recommender 8.33%\n",
      "qqp : logme 50.00%, ptm_recommender 8.33%\n",
      "squad_v2 : logme -, ptm_recommender 8.33%\n"
     ]
    }
   ],
   "source": [
    "DILL_PATH = '../ptm_model_bench/base_model_dataset/'\n",
    "MODEL_PATH = '../results/gcnn_ptm_model_bench/'\n",
    "PERFORMANCE_PATH = '../ptm_model_bench/performance/seen_base_models/'\n",
    "OUTPUT_NAME = 'result'\n",
    "for tdx, task in enumerate(tasks):\n",
    "    if task =='wnli' or task == 'squad_v2':\n",
    "        continue\n",
    "    with  open( f'{PERFORMANCE_PATH}/base_{task}_performance_score.json', 'r') as f:\n",
    "        performance = json.load(f)\n",
    "        performance = performance[task]\n",
    "    if task != 'squad_v2':\n",
    "        with  open( f'{PERFORMANCE_PATH}/base_{task}_logme.json', 'r') as f:\n",
    "            logme = json.load(f)\n",
    "    model_result, test_graph = load_base_model_result(task, performance)\n",
    "    for x in model_result['total_result']:\n",
    "        x['logme'] = logme[x['model_name']]\n",
    "    perf_list =model_result['total_result']\n",
    "    logme_sorted = sorted(perf_list, key=lambda d:-d['logme'])\n",
    "    pred_acc_sorted = sorted(perf_list, key=lambda d:-d['pred_accuracy'])\n",
    "    true_acc_sorted = sorted(perf_list, key=lambda d:-d['true_accuracy'])\n",
    "    logme_selected = logme_sorted[0]['model_name']\n",
    "    gnn_based_selected = pred_acc_sorted[0]['model_name']\n",
    "    for idx, x in enumerate(true_acc_sorted):\n",
    "        if x['model_name'] ==  logme_selected:\n",
    "            logme_rank = (idx+1)/len(true_acc_sorted)\n",
    "        if x['model_name'] ==  gnn_based_selected:\n",
    "            ptm_recommender_rank = (idx+1)/len(true_acc_sorted)\n",
    "    print(task, \": logme {:.2f}%, ptm_recommender {:.2f}%\".format(logme_rank*100,  ptm_recommender_rank*100))\n",
    "\n",
    "task = 'squad_v2'\n",
    "with  open( f'{PERFORMANCE_PATH}/base_{task}_performance_score.json', 'r') as f:\n",
    "    performance = json.load(f)\n",
    "    performance = performance[task]\n",
    "if task != 'squad_v2':\n",
    "    with  open( f'{PERFORMANCE_PATH}/base_{task}_logme.json', 'r') as f:\n",
    "        logme = json.load(f)\n",
    "model_result, test_graph = load_base_model_result(task, performance)\n",
    "perf_list =model_result['total_result']\n",
    "pred_acc_sorted = sorted(perf_list, key=lambda d:-d['pred_accuracy'])\n",
    "true_acc_sorted = sorted(perf_list, key=lambda d:-d['true_accuracy'])\n",
    "gnn_based_selected = pred_acc_sorted[0]['model_name']\n",
    "\n",
    "for idx, x in enumerate(true_acc_sorted):\n",
    "    if x['model_name'] ==  gnn_based_selected:\n",
    "        ptm_recommender_rank = (idx+1)/len(true_acc_sorted)\n",
    "print(task, \": logme {}, ptm_recommender {:.2f}%\".format('-',  ptm_recommender_rank*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa86272f",
   "metadata": {},
   "source": [
    "## Recomendation on unseen base "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "56a16c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cola : logme 10.00%, ptm_recommender 10.00%\n",
      "mnli : logme 10.00%, ptm_recommender 10.00%\n",
      "mrpc : logme 80.00%, ptm_recommender 50.00%\n",
      "qnli : logme 70.00%, ptm_recommender 10.00%\n",
      "rte : logme 10.00%, ptm_recommender 30.00%\n",
      "stsb : logme 70.00%, ptm_recommender 20.00%\n",
      "sst2 : logme 50.00%, ptm_recommender 10.00%\n",
      "qqp : logme 60.00%, ptm_recommender 10.00%\n",
      "squad_v2 : logme -, ptm_recommender 10.00%\n"
     ]
    }
   ],
   "source": [
    "interested_models =[ 'bert-base-cased',\n",
    "                    'bert-large-cased',\n",
    "                    'bert-base-multilingual-uncased',\n",
    "                    'bert-base-multilingual-cased',\n",
    "                    'bert-large-uncased-whole-word-masking',\n",
    "                    'bert-large-cased-whole-word-masking',\n",
    "                    'roberta-base-openai-detector',\n",
    "                    'roberta-large-openai-detector',\n",
    "                    'distilbert-base-cased',\n",
    "                    'distilbert-base-multilingual-cased'\n",
    "                 ]\n",
    "PERFORMANCE_PATH = '../ptm_model_bench/performance/unseen_base_models/'\n",
    "for tdx, task in enumerate(tasks):\n",
    "    if task =='wnli' or task == 'squad_v2':\n",
    "        continue\n",
    "    with  open( f'{PERFORMANCE_PATH}/unrelated_base_{task}_performance_score.json', 'r') as f:\n",
    "        performance = json.load(f)\n",
    "        performance = performance[task]\n",
    "    if task != 'squad_v2':\n",
    "        with  open( f'{PERFORMANCE_PATH}/unrelated_base_{task}_logme.json', 'r') as f:\n",
    "            logme = json.load(f)\n",
    "    model_result, test_graph = load_base_model_result(task, performance, prefix='unseen_base_')\n",
    "    for x in model_result['total_result']:\n",
    "        x['logme'] = logme[x['model_name']]\n",
    "    perf_list =model_result['total_result']\n",
    "    logme_sorted = sorted(perf_list, key=lambda d:-d['logme'])\n",
    "    pred_acc_sorted = sorted(perf_list, key=lambda d:-d['pred_accuracy'])\n",
    "    true_acc_sorted = sorted(perf_list, key=lambda d:-d['true_accuracy'])\n",
    "    logme_selected = logme_sorted[0]['model_name']\n",
    "    gnn_based_selected = pred_acc_sorted[0]['model_name']\n",
    "    for idx, x in enumerate(true_acc_sorted):\n",
    "        if x['model_name'] ==  logme_selected:\n",
    "            logme_rank = (idx+1)/len(true_acc_sorted)\n",
    "        if x['model_name'] ==  gnn_based_selected:\n",
    "            ptm_recommender_rank = (idx+1)/len(true_acc_sorted)\n",
    "    print(task, \": logme {:.2f}%, ptm_recommender {:.2f}%\".format(logme_rank*100,  ptm_recommender_rank*100))\n",
    "\n",
    "task = 'squad_v2'\n",
    "with  open( f'{PERFORMANCE_PATH}/unrelated_base_{task}_performance_score.json', 'r') as f:\n",
    "    performance = json.load(f)\n",
    "    performance = performance[task]\n",
    "model_result, test_graph = load_base_model_result(task, performance, prefix='unseen_base_')\n",
    "perf_list =model_result['total_result']\n",
    "pred_acc_sorted = sorted(perf_list, key=lambda d:-d['pred_accuracy'])\n",
    "true_acc_sorted = sorted(perf_list, key=lambda d:-d['true_accuracy'])\n",
    "gnn_based_selected = pred_acc_sorted[0]['model_name']\n",
    "\n",
    "for idx, x in enumerate(true_acc_sorted):\n",
    "    if x['model_name'] ==  gnn_based_selected:\n",
    "        ptm_recommender_rank = (idx+1)/len(true_acc_sorted)\n",
    "print(task, \": logme {}, ptm_recommender {:.2f}%\".format('-',  ptm_recommender_rank*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7f44b1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert-base-cased': {'exact': 69.2411353491,\n",
       "  'f1': 72.3685457206,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 70.0573549258,\n",
       "  'HasAns_f1': 76.3211442882,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 68.4272497897,\n",
       "  'NoAns_f1': 68.4272497897,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 69.2411353491,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 72.3685457206,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'bert-large-cased': {'exact': 77.2256380022,\n",
       "  'f1': 80.3405868502,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 77.6315789474,\n",
       "  'HasAns_f1': 83.8704095265,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 76.8208578638,\n",
       "  'NoAns_f1': 76.8208578638,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 77.2256380022,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 80.3405868502,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'bert-base-multilingual-uncased': {'exact': 63.9012886381,\n",
       "  'f1': 66.7672928832,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 61.032388664,\n",
       "  'HasAns_f1': 66.7726161272,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 66.7619848612,\n",
       "  'NoAns_f1': 66.7619848612,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 63.8928661669,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 66.7588704121,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'bert-base-multilingual-cased': {'exact': 73.5534405795,\n",
       "  'f1': 76.4167912754,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 70.8839406208,\n",
       "  'HasAns_f1': 76.618853376,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 76.2153069807,\n",
       "  'NoAns_f1': 76.2153069807,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 73.5534405795,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 76.4167912754,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'bert-base-chinese': {'exact': 57.1380443022,\n",
       "  'f1': 60.1098055151,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 49.1565452092,\n",
       "  'HasAns_f1': 55.1085898921,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 65.0967199327,\n",
       "  'NoAns_f1': 65.0967199327,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 57.1380443022,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 60.1098055151,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'bert-base-german-cased': {'exact': 61.366124821,\n",
       "  'f1': 64.3853601352,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 51.0290148448,\n",
       "  'HasAns_f1': 57.0761438741,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 71.6736753574,\n",
       "  'NoAns_f1': 71.6736753574,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 61.3745472922,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 64.3920981121,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'bert-large-uncased-whole-word-masking': {'exact': 72.2479575507,\n",
       "  'f1': 75.3892736933,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 72.705802969,\n",
       "  'HasAns_f1': 78.9974437517,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 71.7914213625,\n",
       "  'NoAns_f1': 71.7914213625,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 72.2479575507,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 75.3892736933,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'bert-large-cased-whole-word-masking': {'exact': 83.4077318285,\n",
       "  'f1': 86.0995693752,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 80.6511470985,\n",
       "  'HasAns_f1': 86.042541699,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 86.1564339781,\n",
       "  'NoAns_f1': 86.1564339781,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 83.4077318285,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 86.0995693752,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'bert-base-german-dbmdz-cased': {'exact': 65.8553019456,\n",
       "  'f1': 68.8657322976,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 59.9021592443,\n",
       "  'HasAns_f1': 65.9316530988,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 71.7914213625,\n",
       "  'NoAns_f1': 71.7914213625,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 65.8553019456,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 68.8657322976,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'bert-base-german-dbmdz-uncased': {'exact': 59.2268171482,\n",
       "  'f1': 62.3977413171,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 53.0026990553,\n",
       "  'HasAns_f1': 59.3536407993,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 65.43313709,\n",
       "  'NoAns_f1': 65.43313709,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 59.3110418597,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 62.3977413171,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'bert-base-japanese': {'exact': 60.1448665038,\n",
       "  'f1': 63.6792134554,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 53.6605937922,\n",
       "  'HasAns_f1': 60.7394233056,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 66.6105971405,\n",
       "  'NoAns_f1': 66.6105971405,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 60.1448665038,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 63.6792134554,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'bert-base-japanese-whole-word-masking': {'exact': 62.6126505517,\n",
       "  'f1': 65.8439931205,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 55.1113360324,\n",
       "  'HasAns_f1': 61.5832878408,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 70.0925147183,\n",
       "  'NoAns_f1': 70.0925147183,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 62.629495494,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 65.8608380628,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'bert-base-japanese-char': {'exact': 59.496336225,\n",
       "  'f1': 62.7015640022,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 45.1079622132,\n",
       "  'HasAns_f1': 51.5276095476,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 73.8435660219,\n",
       "  'NoAns_f1': 73.8435660219,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 59.496336225,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 62.7015640022,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'bert-base-finnish-cased-v1': {'exact': 66.0237513687,\n",
       "  'f1': 69.3004843428,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 56.9669365722,\n",
       "  'HasAns_f1': 63.5297993594,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 75.0546677881,\n",
       "  'NoAns_f1': 75.0546677881,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 66.0237513687,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 69.3004843428,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'bert-base-finnish-uncased-v1': {'exact': 58.6625115809,\n",
       "  'f1': 61.611870936,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 49.628879892,\n",
       "  'HasAns_f1': 55.5360566167,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 67.6703111859,\n",
       "  'NoAns_f1': 67.6703111859,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 58.6456666386,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 61.5950259937,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'bert-base-dutch-cased': {'exact': 63.7159942727,\n",
       "  'f1': 66.986917326,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 55.4149797571,\n",
       "  'HasAns_f1': 61.9662060412,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 71.9932716569,\n",
       "  'NoAns_f1': 71.9932716569,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 63.7159942727,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 66.986917326,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'roberta-large-mnli': {'exact': 84.6711025015,\n",
       "  'f1': 88.0268920408,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 80.7692307692,\n",
       "  'HasAns_f1': 87.490433401,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 88.5618166526,\n",
       "  'NoAns_f1': 88.5618166526,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 84.645835088,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 88.0016246274,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'roberta-base-openai-detector': {'exact': 77.4193548387,\n",
       "  'f1': 80.8699004967,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 75.8771929825,\n",
       "  'HasAns_f1': 82.788179588,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 78.9571068124,\n",
       "  'NoAns_f1': 78.9571068124,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 77.4193548387,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 80.8699004967,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'roberta-large-openai-detector': {'exact': 84.8479743957,\n",
       "  'f1': 88.0149829905,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 82.4224021592,\n",
       "  'HasAns_f1': 88.7655015261,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 87.2666105971,\n",
       "  'NoAns_f1': 87.2666105971,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 84.1657542323,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 87.3327628271,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'distilbert-base-cased': {'exact': 63.8844436958,\n",
       "  'f1': 66.9276993168,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 62.7699055331,\n",
       "  'HasAns_f1': 68.8651440601,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 64.9957947855,\n",
       "  'NoAns_f1': 64.9957947855,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 63.9012886381,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 66.9445442591,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'distilbert-base-german-cased': {'exact': 50.5432493894,\n",
       "  'f1': 53.7821629978,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 39.6086369771,\n",
       "  'HasAns_f1': 46.0957525765,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 61.4465937763,\n",
       "  'NoAns_f1': 61.4465937763,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 50.9980628316,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 53.9506010385,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'distilbert-base-multilingual-cased': {'exact': 63.9012886381,\n",
       "  'f1': 67.21428508,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 62.0614035088,\n",
       "  'HasAns_f1': 68.6968972259,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 65.7359125315,\n",
       "  'NoAns_f1': 65.7359125315,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 63.9097111092,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 67.2227075512,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'camembert-base': {'exact': 70.3192116567,\n",
       "  'f1': 73.2315131082,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 62.8036437247,\n",
       "  'HasAns_f1': 68.6365983694,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 77.8132884777,\n",
       "  'NoAns_f1': 77.8132884777,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 70.3192116567,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 73.2315131082,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'flaubert_small_cased': {'exact': 46.9552766782,\n",
       "  'f1': 47.4538270262,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 6.9669365722,\n",
       "  'HasAns_f1': 7.9654669841,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 86.8292682927,\n",
       "  'NoAns_f1': 86.8292682927,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 50.1642381875,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 50.2214234375,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'flaubert_base_uncased': {'exact': 1.2717931441,\n",
       "  'f1': 4.3717141831,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 0.1012145749,\n",
       "  'HasAns_f1': 6.30994644,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 2.4390243902,\n",
       "  'NoAns_f1': 2.4390243902,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 50.0715910048,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 50.0739974251,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'flaubert_base_cased': {'exact': 59.8163901289,\n",
       "  'f1': 62.9240758689,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 49.6457489879,\n",
       "  'HasAns_f1': 55.8700325221,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 69.9579478553,\n",
       "  'NoAns_f1': 69.9579478553,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 59.8248126,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 62.9268833593,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'flaubert_large_cased': {'exact': 71.2035711278,\n",
       "  'f1': 74.1970361211,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 66.2618083671,\n",
       "  'HasAns_f1': 72.2573228519,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 76.1312026913,\n",
       "  'NoAns_f1': 76.1312026913,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 71.2035711278,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 74.1970361211,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'small-base': {'exact': 67.6829781858,\n",
       "  'f1': 71.4448296899,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 69.8717948718,\n",
       "  'HasAns_f1': 77.4062859158,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 65.5004205214,\n",
       "  'NoAns_f1': 65.5004205214,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 67.6661332435,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 71.4279847476,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'medium-base': {'exact': 69.8222858587,\n",
       "  'f1': 73.4084845597,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 70.3272604588,\n",
       "  'HasAns_f1': 77.509942169,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 69.3187552565,\n",
       "  'NoAns_f1': 69.3187552565,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 69.8222858587,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 73.4084845597,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'intermediate-base': {'exact': 70.1676071759,\n",
       "  'f1': 73.6215078129,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 72.0479082321,\n",
       "  'HasAns_f1': 78.9656144169,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 68.2926829268,\n",
       "  'NoAns_f1': 68.2926829268,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 70.1591847048,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 73.6130853418,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'large-base': {'exact': 66.4364524552,\n",
       "  'f1': 69.6753396448,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 66.8690958165,\n",
       "  'HasAns_f1': 73.3561585024,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 66.0050462574,\n",
       "  'NoAns_f1': 66.0050462574,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 66.4364524552,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 69.6753396448,\n",
       "  'best_f1_thresh': 0.0},\n",
       " 'xlm-roberta-base': {'exact': 73.8482270698,\n",
       "  'f1': 76.8733728055,\n",
       "  'total': 11873,\n",
       "  'HasAns_exact': 71.2381916329,\n",
       "  'HasAns_f1': 77.2971584547,\n",
       "  'HasAns_total': 5928,\n",
       "  'NoAns_exact': 76.4507989907,\n",
       "  'NoAns_f1': 76.4507989907,\n",
       "  'NoAns_total': 5945,\n",
       "  'best_exact': 73.8229596564,\n",
       "  'best_exact_thresh': 0.0,\n",
       "  'best_f1': 76.848105392,\n",
       "  'best_f1_thresh': 0.0}}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bb2c2977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_result': [{'true_accuracy': 0.860995693752,\n",
       "   'pred_accuracy': 0.6209824,\n",
       "   'model_name': 'bert-large-cased-whole-word-masking'},\n",
       "  {'true_accuracy': 0.753892736933,\n",
       "   'pred_accuracy': 0.6198833,\n",
       "   'model_name': 'bert-large-uncased-whole-word-masking'},\n",
       "  {'true_accuracy': 0.667672928832,\n",
       "   'pred_accuracy': 0.6178845,\n",
       "   'model_name': 'bert-base-multilingual-uncased'},\n",
       "  {'true_accuracy': 0.6721428507999999,\n",
       "   'pred_accuracy': 0.59631,\n",
       "   'model_name': 'distilbert-base-multilingual-cased'},\n",
       "  {'true_accuracy': 0.880149829905,\n",
       "   'pred_accuracy': 0.7760251,\n",
       "   'model_name': 'roberta-large-openai-detector'},\n",
       "  {'true_accuracy': 0.669276993168,\n",
       "   'pred_accuracy': 0.5926028,\n",
       "   'model_name': 'distilbert-base-cased'},\n",
       "  {'true_accuracy': 0.808699004967,\n",
       "   'pred_accuracy': 0.71738327,\n",
       "   'model_name': 'roberta-base-openai-detector'},\n",
       "  {'true_accuracy': 0.803405868502,\n",
       "   'pred_accuracy': 0.6240389,\n",
       "   'model_name': 'bert-large-cased'},\n",
       "  {'true_accuracy': 0.723685457206,\n",
       "   'pred_accuracy': 0.5980908,\n",
       "   'model_name': 'bert-base-cased'},\n",
       "  {'true_accuracy': 0.764167912754,\n",
       "   'pred_accuracy': 0.6183559,\n",
       "   'model_name': 'bert-base-multilingual-cased'}]}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd9f8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
